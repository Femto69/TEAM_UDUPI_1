# -*- coding: utf-8 -*-
"""aqi_pred_weather

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n0uEZ3H1siN6e05GAJMOCZM91mUpPOya
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error as mae
from sklearn.metrics import mean_squared_error as mse

data_1 = pd.read_csv('/content/deli_aqi_date.zip')

data = pd.read_csv('/content/delhi_aqi_weather.zip')

data_1['datetime'] = pd.to_datetime(data_1['date'])
data_1['Date_1'] = data_1['datetime'].dt.date
data_1['year'] = data_1['datetime'].dt.year
data_1['month'] = data_1['datetime'].dt.month
data_1['Day'] = data_1['datetime'].dt.day
data_1['Weekday'] = data_1['datetime'].dt.day_name()   # Converting the 'date' column to datetime
data_1['hour'] = data_1['datetime'].dt.hour          # Extracting the hour

data_1.head()

def season_creation(x):
    if x in [2,3,4]:
        season = "Spring"
    elif x in [5,6]:
        season = "Summer"
    elif x in [7,8]:
        season = "Monsoon"
    elif x in [9,10]:
        season = "Autumn"
    elif x in[11,12,1]:
        season = "Winter"
    return season

data_1["Season"] = data_1["month"].apply(season_creation)
data_1.head()

data.shape

data.isnull().sum()

data.head()

data.info()

data.drop(['Unnamed: 0'],axis=1,inplace=True)

data.head()

data.columns= ['avg temp','max temp','min temp','pressure','humidity','visibility' ,'avg wind speed','max wind speed' , 'aqi']

data.head()

mean_value = data['aqi'].mean()

data['aqi'] = data['aqi'].fillna(mean_value)

data.info()

X = data.drop(['aqi'],axis=1)
Y = data['aqi']
X1 = data['aqi']
Y1 = data['visibility']
print(X1,Y1)

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=3)

X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, Y1, test_size=0.2, random_state=3)

models = [RandomForestRegressor(), DecisionTreeRegressor(), XGBRegressor()]
def compare_models_cross_validation():
  for model in models:
    cv_score = cross_val_score(model, X, Y, scoring='neg_mean_absolute_error', cv=5)
    mean_mae = -cv_score.mean()
    print('mae for', model, 'is', mean_mae)

compare_models_cross_validation()

# Define the model and the hyperparameter grid
#rf = RandomForestRegressor()
#rf_params = {
   #'n_estimators': [100, 200, 300],  # Reduce the number of options
  #  'max_features': ['auto', 'sqrt'],
    #'max_depth': [None, 10, 20],
#     'min_samples_split': [2, 5],
  #   'criterion': ['squared_error', 'absolute_error']  # Keep only the essential criteria
#}

# Perform GridSearchCV
#rf_grid_search = GridSearchCV(estimator=rf, param_grid=rf_params, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)
#rf_grid_search.fit(X, Y)

# Print the best parameters and the corresponding score
#print("Best parameters for RandomForestRegressor:")
#print(rf_grid_search.best_params_)
#print("Best score:", rf_grid_search.best_score_)

#from xgboost import XGBRegressor
#from sklearn.model_selection import GridSearchCV

# Define the model and the hyperparameter grid
#xgb = XGBRegressor()
#xgb_params = {
 #   'n_estimators': [100, 200],  # Reduce the number of options
  #  'max_depth': [3, 6],
   # 'learning_rate': [0.01, 0.1],
    #'subsample': [0.8, 1.0],  # Keep it simple
 #  'gamma': [0, 0.1]
#}

# Perform GridSearchCV
#xgb_grid_search = GridSearchCV(estimator=xgb, param_grid=xgb_params, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)
#xgb_grid_search.fit(X, Y)

# Print the best parameters and the corresponding score
#print("Best parameters for XGBRegressor:")
#print(xgb_grid_search.best_params_)
#print("Best score:", xgb_grid_search.best_score_)

model1 = XGBRegressor()

model = XGBRegressor()

#model = XGBRegressor(n_estimators=200, max_depth=6, learning_rate=0.1, subsample=0.8, colsample_bytree=0.8, gamma=0)

model.fit(X_train, y_train)

model1.fit(X_train1, y_train1)

test_pred1 = model1.predict(X_test1)
mean_abs_error1 = mae(y_test1, test_pred1)
print(mean_abs_error1)

p = data_1['pm2_5']
P = np.array(p)

visibility_pred = model1.predict(P.reshape(-1, 1))
data_1['visibility'] = visibility_pred
data_1.head()

df = data_1.groupby('month')['visibility'].mean()
print(df)

test_pred = model.predict(X_test)

mean_abs_error = mae(y_test, test_pred)

print(mean_abs_error)

new_data = np.array([[31,38,31,988,89,1.959329,1,4]])  # temperature, pressure, humidity
predicted_aqi = model.predict(new_data)
print("Predicted AQI:", predicted_aqi)

#model = XGBRegressor()

#model.fit(X_train, y_train)

#test_pred = model.predict(X_test)

#mean_abs_error = mae(y_test, test_pred)

#print(mean_abs_error)

#new_data = np.array([[35,37,31,981,60,2,4,5]])  # temperature, pressure, humidity
#predicted_aqi = model.predict(new_data)
#print("Predicted AQI:", predicted_aqi)

corr_matrix = data.corr()
print(corr_matrix)

plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.show()

